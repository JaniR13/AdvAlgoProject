\documentclass[]{article}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}

%opening
\title{Project Part 2}
\author{Group 6: Janette Rounds, David Rice, Mitch Vander Linden}

\begin{document}

\maketitle

\section{Introduction}

\section{Bayesian Classifier Learning Algorithm}
In the field of Machine Learning, there are many models based off of Bayes Theorem: 
$$P(x|y) = \frac{P(y|x)P(x)}{P(y)}$$ where $x$ and $y$ are events, and $P(x)$ is the probability of $x$ \cite{koller2009probabilistic}.  In short, Bayes Theorem states that the probability of an event $x$, given that we know event $y$ happened, is proportional to the probability of event $y$ given event $x$ times the probability of $x$. Bayes Theorem allows us to use prior information about a domain or a model in order to assess what can be thought of as a "degree of belief". 

There are two Bayesian methods that we are concerned with in \cite[Liu 2013]{liu2013bayesian}, Bayesian Optimization and Naive Bayes Classification (NB).  NB is a powerful Machine Learning method that allows us to assign a category (or a label) to an observation based on a training data set \cite{koller2009probabilistic}. NB is a powerful model, but it also has some very strong assumptions, primarily that all attributes (variables that help us figure out which label to assign) are independent of one another. There are countless domains and problems where this assumption does not hold. 

Our other Bayesian method of interest is Bayesian Optimization (BO). BO involves approximating functions, especially functions that are computationally expensive, where derivatives do not exist or are unknown, or where there are only a few observations available \cite{brochu2010tutorial}. In \cite[Liu 2013]{liu2013bayesian}, the authors show that, through an algorithm that converts the BO model into a classifier, we can create a Bayesian Classifier without the strong independence assumption of Naive Bayes Classifiers. 

\section{Tree Counting Algorithm}
\cite[Santoro 2013]{santoro2013tree}
\section{Automated Scheduling Algorithm}
The question of efficient crop irrigation is one of great importance in agricultural pursuits of all kinds. On the one hand, the results of under-watering are quite apparent. In contrast, over-watering can also have detrimental effects, and in many climates water is a limited resource that cannot be wasted.

This algorithm aims to solve the problem of automated scheduling of drip irrigation in tree crops by efficiently streamline seven distinct but related tasks: estimation of irrigation needs, adaptation to the irrigation setup, execution of the schedule, plant and soil monitoring, automated interpretation of data, reaction to unforeseen events, and continuous tuning of the model\cite[Casadesus 2012]{casadesus2012drip}. It is this final constraint that requires the algorithm to implement machine learning - by constantly fine-tuning the irrigation process based on recent data, it attempts to construct a solution that is best-fit to the current conditions.
\cite[Casadesus 2012]{casadesus2012drip}
\bibliographystyle{ieeetr}
\bibliography{bib1}

\end{document}
